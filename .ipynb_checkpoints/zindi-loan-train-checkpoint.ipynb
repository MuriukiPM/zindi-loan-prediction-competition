{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable reloading of modules being used after they change during the instance\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display             # Allows the use of display() for DataFrames\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from imblearn.combine import SMOTEENN, _smote_enn\n",
    "from imblearn.pipeline import pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning \n",
    "warnings.filterwarnings(action='ignore',category=DataConversionWarning) #to supress dataconversion warnings from scaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Import the classes\n",
    "from libs.utils import *\n",
    "\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindemog_df = pd.read_csv(\"./data/traindemographics.csv\", names=None, header=0) \n",
    "trainperf_df = pd.read_csv(\"./data/trainperf.csv\", header=0)\n",
    "trainprev_df = pd.read_csv(\"./data/trainprevloans.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the repeated rows for each costuomerid in demographics\n",
    "traindemog_df.drop_duplicates(subset=['customerid'], inplace=True)\n",
    "# edit the bank names to remove spaces\n",
    "#traindemog_df['bank_name_clients'] = traindemog_df['bank_name_clients'].apply(lambda x: '_'.join(x.split()))\n",
    "# Alternative: drop bank_name_clients column\n",
    "traindemog_df.drop(columns=['bank_name_clients'], inplace=True)\n",
    "# merge demographics with perfomance. Performance taking priority\n",
    "merged_df = trainperf_df.merge(traindemog_df, on=['customerid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainprev_features = FeatureUnion([\n",
    "    ('prev_termdaysmean', GetMean('termdays')),\n",
    "    ('prev_daysearlymean', DaydeltaTransformer('firstduedate','firstrepaiddate', 'daysearly')),\n",
    "    ('prev_dayslatemean', DaydeltaTransformer('firstrepaiddate', 'firstduedate', 'dayslate')),\n",
    "    ('prev_loanamountmean', GetMean('loanamount')),\n",
    "    ('prev_wait_timemean', TimedeltaTransformer('approveddate', 'creationdate', 'b4approval')),\n",
    "    ('prev_referredcount', GetUnique('referredby')),\n",
    "    ('customerid', GetUid('customerid'))\n",
    "])\n",
    "trainprev_df_ = pd.DataFrame(data=trainprev_features.fit_transform(trainprev_df),\n",
    "                            columns=['prev_termdaysmean','prev_daysearlymean',\n",
    "                                     'prev_dayslatemean','prev_loanamountmean',\n",
    "                                     'prev_wait_timemean','prev_referredcount','customerid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge new columns to the merged df. Merged df taking priority. Ensure float dtype for new cols\n",
    "merged_df = merged_df.merge(trainprev_df_, on=['customerid'], how='left')\n",
    "merged_df = merged_df.astype({'prev_termdaysmean':'float64',\n",
    "                               'prev_daysearlymean':'float64',\n",
    "                               'prev_dayslatemean':'float64',\n",
    "                               'prev_loanamountmean':'float64',\n",
    "                               'prev_wait_timemean':'float64',\n",
    "                               'prev_referredcount':'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation depends on full dataset\n",
    "subpipe = make_pipeline(\n",
    "    AgeYears('birthdate', 'approveddate', 'age_years'),\n",
    "    StatFillNa('prev_termdaysmean', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('prev_daysearlymean', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('prev_dayslatemean', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('prev_loanamountmean', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('prev_wait_timemean', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('prev_referredcount', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('age_years', 'good_bad_flag', 'Median'),\n",
    ")\n",
    "merged_df = subpipe.fit_transform(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['customerid', 'good_bad_flag', 'systemloanid', 'totaldue', 'referredby',\n",
    "           'bank_branch_clients', 'level_of_education_clients',\n",
    "          'longitude_gps', 'latitude_gps']\n",
    "categorical_features = ['bank_account_type', 'employment_status_clients']#, 'bank_name_clients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpipe = make_pipeline(\n",
    "    ReferredTransformer('referredby', 'referred_status'),\n",
    "    ApprovalPeriod('approveddate','creationdate','b4approval_sec'),\n",
    "    VarFillNa('bank_account_type', 'Other'),\n",
    "    VarFillNa('employment_status_clients',' Unknown'),\n",
    "    #VarFillNa('bank_name_clients', 'Unknown'),\n",
    "    Encoder(categorical_features),\n",
    "    ColumnDropTransformer(to_drop),\n",
    "    #SMOTEENN(random_state=42, ratio=0.8),\n",
    "    StandardScaler()\n",
    "    #GradientBoostingClassifier(random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the prepared data to test with tensorflow\n",
    "np.savetxt('./data/ytest.csv', y_test.values, delimiter=',')\n",
    "np.savetxt('./data/ytrain.csv', y_train.values, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = merged_df['good_bad_flag'] # Target class column\n",
    "X = mainpipe.fit_transform(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(*shuffle(X, (y=='Good').astype(int)),\n",
    "                                                     test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the prepared data to test with tensorflow\n",
    "np.savetxt('./data/xtrain.csv', X_train,delimiter=',')\n",
    "np.savetxt('./data/xtest.csv', X_test, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clfModel = mainpipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clfModel.predict(X_test)\n",
    "trainingtest = clfModel.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.26      0.34       281\n",
      "           1       0.82      0.92      0.87      1030\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1311\n",
      "   macro avg       0.65      0.59      0.61      1311\n",
      "weighted avg       0.75      0.78      0.76      1311\n",
      "\n",
      "tn: 74, fp: 207, fn: 78, tp: 952\n",
      "Training Accuracy score: 0.8475629702322538\n",
      "Test Accuracy score: 0.782608695652174\n",
      "Test F1 score: 0.8698035632709\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))\n",
    "#print(classification_report(y, trainingtest))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "#tn, fp, fn, tp = confusion_matrix(y, trainingtest).ravel()\n",
    "print('tn: '+str(tn)+', fp: '+str(fp)+', fn: '+str(fn)+', tp: '+str(tp))\n",
    "print('Training Accuracy score:', accuracy_score(y_train, trainingtest))\n",
    "print('Test Accuracy score:', accuracy_score(y_test, predictions))\n",
    "print('Test F1 score:', f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clfModel.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmainpipe = Pipeline([\\n    #('referred_status', ReferredTransformer('referredby', 'referred_status')),\\n    #('b4approval_sec', ApprovalPeriod('approveddate','creationdate','b4approval_sec')),\\n    #('bank_account', VarFillNa('bank_account_type', 'Other')),\\n    #('employment', VarFillNa('employment_status_clients',' Unknown')),\\n    #('bank_name', VarFillNa('bank_name_clients', 'Unknown')),\\n    ('age_years', StatFillNa('age_years', 'good_bad_flag', 'Median')),\\n    #('encoder', Encoder(categorical_features)),\\n    ('drop', ColumnDropTransformer(to_drop)),\\n    #('smote', SMOTE(random_state=42, ratio = 0.9)),\\n    #('enn', EditedNearestNeighbours(random_state=42)),\\n    #('scaler', StandardScaler()),\\n    #('clf', GradientBoostingClassifier(n_estimators=500, random_state=42))\\n])\\nmainpipe.fit_transform(merged_df).info()\\n#clfModel\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "mainpipe = Pipeline([\n",
    "    #('referred_status', ReferredTransformer('referredby', 'referred_status')),\n",
    "    #('b4approval_sec', ApprovalPeriod('approveddate','creationdate','b4approval_sec')),\n",
    "    #('bank_account', VarFillNa('bank_account_type', 'Other')),\n",
    "    #('employment', VarFillNa('employment_status_clients',' Unknown')),\n",
    "    #('bank_name', VarFillNa('bank_name_clients', 'Unknown')),\n",
    "    ('age_years', StatFillNa('age_years', 'good_bad_flag', 'Median')),\n",
    "    #('encoder', Encoder(categorical_features)),\n",
    "    ('drop', ColumnDropTransformer(to_drop)),\n",
    "    #('smote', SMOTE(random_state=42, ratio = 0.9)),\n",
    "    #('enn', EditedNearestNeighbours(random_state=42)),\n",
    "    #('scaler', StandardScaler()),\n",
    "    #('clf', GradientBoostingClassifier(n_estimators=500, random_state=42))\n",
    "])\n",
    "mainpipe.fit_transform(merged_df).info()\n",
    "#clfModel\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
