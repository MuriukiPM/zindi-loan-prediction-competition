{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmuriuki/.local/lib/python3.5/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from imblearn.combine import SMOTEENN, _smote_enn\n",
    "from imblearn.pipeline import pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning \n",
    "warnings.filterwarnings(action='ignore',category=DataConversionWarning) #to supress dataconversion warnings from scaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindemog_df = pd.read_csv(\"./data/traindemographics.csv\", names=None, header=0) \n",
    "trainperf_df = pd.read_csv(\"./data/trainperf.csv\", header=0)\n",
    "trainprev_df = pd.read_csv(\"./data/trainprevloans.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the repeated rows for each costuomerid in demographics\n",
    "traindemog_df.drop_duplicates(subset=['customerid'], inplace=True)\n",
    "# edit the bank names to remove spaces\n",
    "traindemog_df['bank_name_clients'] = traindemog_df['bank_name_clients'].apply(lambda x: '_'.join(x.split()))\n",
    "# Alternative: drop bank_name_clients column\n",
    "#traindemog_df.drop(columns=['bank_name_clients'], inplace=True)\n",
    "# merge demographics with perfomance. Performance taking priority\n",
    "merged_df = trainperf_df.merge(traindemog_df, on=['customerid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classes\n",
    "from libs.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainprev_features = FeatureUnion([\n",
    "    ('prev_termdaysmean', GetMean('termdays')),\n",
    "    ('prev_daysearlymean', DaydeltaTransformer('firstduedate','firstrepaiddate', 'daysearly')),\n",
    "    ('prev_dayslatemean', DaydeltaTransformer('firstrepaiddate', 'firstduedate', 'dayslate')),\n",
    "    ('prev_loanamountmean', GetMean('loanamount')),\n",
    "    ('prev_wait_timemean', TimedeltaTransformer('approveddate', 'creationdate', 'b4approval')),\n",
    "    ('prev_referredcount', GetUnique('referredby')),\n",
    "    ('customerid', GetUid('customerid'))\n",
    "])\n",
    "trainprev_df_ = pd.DataFrame(data=trainprev_features.fit_transform(trainprev_df),\n",
    "                            columns=['prev_termdaysmean','prev_daysearlymean',\n",
    "                                     'prev_dayslatemean','prev_loanamountmean',\n",
    "                                     'prev_wait_timemean','prev_referredcount','customerid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge new columns to the merged df. Merged df taking priority. Ensure float dtype for new cols\n",
    "merged_df = merged_df.merge(trainprev_df_, on=['customerid'], how='left')\n",
    "merged_df = merged_df.astype({'prev_termdaysmean':'float64',\n",
    "                               'prev_daysearlymean':'float64',\n",
    "                               'prev_dayslatemean':'float64',\n",
    "                               'prev_loanamountmean':'float64',\n",
    "                               'prev_wait_timemean':'float64',\n",
    "                               'prev_referredcount':'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation depends on full dataset\n",
    "subpipe = make_pipeline(\n",
    "    AgeYears('birthdate', 'approveddate', 'age_years'),\n",
    "    StatFillNa('prev_termdaysmean', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('prev_daysearlymean', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('prev_dayslatemean', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('prev_loanamountmean', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('prev_wait_timemean', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('prev_referredcount', 'good_bad_flag', 'Mean'),\n",
    "    StatFillNa('age_years', 'good_bad_flag', 'Median'),\n",
    ")\n",
    "merged_df = subpipe.fit_transform(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['customerid', 'good_bad_flag', 'systemloanid', 'totaldue', 'referredby',\n",
    "           'bank_branch_clients', 'level_of_education_clients',\n",
    "          'longitude_gps', 'latitude_gps']\n",
    "categorical_features = ['bank_account_type', 'bank_name_clients', 'employment_status_clients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpipe = make_pipeline(\n",
    "    ReferredTransformer('referredby', 'referred_status'),\n",
    "    ApprovalPeriod('approveddate','creationdate','b4approval_sec'),\n",
    "    VarFillNa('bank_account_type', 'Other'),\n",
    "    VarFillNa('employment_status_clients',' Unknown'),\n",
    "    VarFillNa('bank_name_clients', 'Unknown'),\n",
    "    Encoder(categorical_features),\n",
    "    ColumnDropTransformer(to_drop),\n",
    "    #SMOTEENN(random_state=42, ratio=0.8),\n",
    "    StandardScaler(),\n",
    "    SVC(class_weight='balanced', random_state=42)\n",
    ")\n",
    "\n",
    "y = merged_df['good_bad_flag'] # Target class column\n",
    "X_train, X_test, y_train, y_test = train_test_split(*shuffle(merged_df, (y=='Good').astype(int)),\n",
    "                                                    test_size=0.30, random_state=42)\n",
    "clfModel = mainpipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1311,37) (38,) (1311,37) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b2c42b1cd644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclfModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainingtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclfModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    347\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1311,37) (38,) (1311,37) "
     ]
    }
   ],
   "source": [
    "predictions = clfModel.predict(X_test)\n",
    "trainingtest = clfModel.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "#print(classification_report(y, trainingtest))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "#tn, fp, fn, tp = confusion_matrix(y, trainingtest).ravel()\n",
    "print('tn: '+str(tn)+', fp: '+str(fp)+', fn: '+str(fn)+', tp: '+str(tp))\n",
    "print('Training Accuracy score:', accuracy_score(y_train, trainingtest))\n",
    "print('Test Accuracy score:', accuracy_score(y_test, predictions))\n",
    "print('Test F1 score:', f1_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clfModel.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmainpipe = Pipeline([\\n    #('referred_status', ReferredTransformer('referredby', 'referred_status')),\\n    #('b4approval_sec', ApprovalPeriod('approveddate','creationdate','b4approval_sec')),\\n    #('bank_account', VarFillNa('bank_account_type', 'Other')),\\n    #('employment', VarFillNa('employment_status_clients',' Unknown')),\\n    #('bank_name', VarFillNa('bank_name_clients', 'Unknown')),\\n    ('age_years', StatFillNa('age_years', 'good_bad_flag', 'Median')),\\n    #('encoder', Encoder(categorical_features)),\\n    ('drop', ColumnDropTransformer(to_drop)),\\n    #('smote', SMOTE(random_state=42, ratio = 0.9)),\\n    #('enn', EditedNearestNeighbours(random_state=42)),\\n    #('scaler', StandardScaler()),\\n    #('clf', GradientBoostingClassifier(n_estimators=500, random_state=42))\\n])\\nmainpipe.fit_transform(merged_df).info()\\n#clfModel\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "mainpipe = Pipeline([\n",
    "    #('referred_status', ReferredTransformer('referredby', 'referred_status')),\n",
    "    #('b4approval_sec', ApprovalPeriod('approveddate','creationdate','b4approval_sec')),\n",
    "    #('bank_account', VarFillNa('bank_account_type', 'Other')),\n",
    "    #('employment', VarFillNa('employment_status_clients',' Unknown')),\n",
    "    #('bank_name', VarFillNa('bank_name_clients', 'Unknown')),\n",
    "    ('age_years', StatFillNa('age_years', 'good_bad_flag', 'Median')),\n",
    "    #('encoder', Encoder(categorical_features)),\n",
    "    ('drop', ColumnDropTransformer(to_drop)),\n",
    "    #('smote', SMOTE(random_state=42, ratio = 0.9)),\n",
    "    #('enn', EditedNearestNeighbours(random_state=42)),\n",
    "    #('scaler', StandardScaler()),\n",
    "    #('clf', GradientBoostingClassifier(n_estimators=500, random_state=42))\n",
    "])\n",
    "mainpipe.fit_transform(merged_df).info()\n",
    "#clfModel\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
